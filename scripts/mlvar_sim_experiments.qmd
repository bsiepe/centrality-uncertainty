---
title: "mlVAR Simulation"
format: html
---

# Background
In this document, we try to adapt the `mlVAR::mlVARsim` function to our purposes
```{r}
library(mvtnorm)
library(here)
library(mlVAR)
library(tidyverse)
```


# Trying mlVARsim_mod 
Copied from: https://github.com/SachaEpskamp/mlVAR/blob/master/R/mlVARmodel.R

```{r}
# Graph simulator:
simGraph <- function(
  Nvar,
  sparsity = 0.5,
  parRange = c(0.5,1),
  constant = 1.1,
  propPositive = 0.5
){
  ## Approach from 
  # Yin, J., & Li, H. (2011). A sparse conditional gaussian graphical model for analysis of genetical genomics data. The annals of applied statistics, 5(4), 2630.
  
  # Empty matrix:
  trueKappa <- matrix(0,Nvar,Nvar)
  
  # Total edges:
  totEdges <- sum(upper.tri(trueKappa))
  
  # Included edges:
  nEdges <- round((1-sparsity)*totEdges)
  
  # Sample the edges:
  inclEdges <- sample(seq_len(totEdges),nEdges)
  
  # Make edges:
  trueKappa[upper.tri(trueKappa)][inclEdges] <- 1
  
  # Make edges negative and add weights:
  trueKappa[upper.tri(trueKappa)] <- trueKappa[upper.tri(trueKappa)] * sample(c(-1,1),sum(upper.tri(trueKappa)),TRUE,prob=c(propPositive,1-propPositive)) * 
    runif(sum(upper.tri(trueKappa)), min(parRange ),max(parRange ))
  
  # Symmetrize:
  trueKappa[lower.tri(trueKappa)] <- t(trueKappa)[lower.tri(trueKappa)]  
  
  # Make pos def:
  diag(trueKappa) <- constant * rowSums(abs(trueKappa))
  diag(trueKappa) <- ifelse(diag(trueKappa)==0,1,diag(trueKappa))
  trueKappa <- trueKappa/diag(trueKappa)[row(trueKappa)]
  trueKappa <- (trueKappa + t(trueKappa)) / 2
  
  return(as.matrix(qgraph::wi2net(trueKappa)))
}



# 1. fixed effects (means) for every parameter and a variance-covariance matrix.
# 2. Generate Beta's 
# 3. Shrink all beta's until all eigenvalues are in unit circle.
# If I simulate with fixed effects variance of 1, then the effects are standardized?

# Now also implemented taking temporal fixed effects and means from a fitted mlVAR model
mlVARsim_mod <- function(
  # Simulation setup:
  nPerson = 10, # # of persons.
  nNode = 5, # # of nodes 
  nTime = 100, # Or vector with time points per person. 
  lag = 1,
  empirical_model = NULL, # use fitted mlVAR model fixed effects coefficients
  thetaVar = rep(1,nNode),
  DF_theta = nNode*2,
  mu_SD = c(1,1),
  init_beta_SD = c(0.1,1),
  fixedMuSD = 1,
  fixedBetaSD = 1,
  shrink_fixed = 0.9,
  shrink_deviation = 0.9,
  pcor_sparsity = 0.5,
  beta_sparsity = 0.5
){
  # browser()
  contemporaneous <- "wishart"
  GGMsparsity = pcor_sparsity
  
  if (length(nTime)==1){
    nTime <- rep(nTime,nPerson)
  }
  # Number of temporal effects:
  nTemporal <- nNode^2 * lag
  
  # 1. Generate structures
  # Generate Omega:

  # Simulate mu means:
  Omega_mu <- cov2cor(solve(diag(nNode)-simGraph(nNode)))
  # Simulate temporal:
  Omega_Beta <- cov2cor(solve(diag(nTemporal)-simGraph(nTemporal)))
  

  Omega <- rbind(
    cbind(Omega_mu, matrix(0,nNode,nTemporal)),
    cbind(matrix(0,nTemporal,nNode), Omega_Beta)
  )

  
  # Generate SD and scale:
  # BS: I think the nNode here may be wrong? it should be nNode + nTemporal
  # SD <- runif(nNode + nTemporal, c(rep(mu_SD[1],nNode),rep(init_beta_SD[1],nNode)), c(rep(mu_SD[2],nNode),rep(init_beta_SD[2],nNode)))
  SD <- runif(nNode + nTemporal, c(rep(mu_SD[1],nNode),rep(init_beta_SD[1],nTemporal)), c(rep(mu_SD[2],nNode),rep(init_beta_SD[2],nTemporal)))
  

  Omega <- diag(SD) %*%Omega %*% diag(SD)
  


  # Generate fixed contemporaneous:
  if (contemporaneous=="wishart"){
    Theta_fixed <- cov2cor(solve(diag(nNode)-simGraph(nNode)))
    Theta_fixed <- diag(sqrt(thetaVar)) %*% Theta_fixed %*% diag(sqrt(thetaVar))
    
    # 2. Generate residual covariance matrices:
    Theta <- rWishart(nPerson, DF_theta, Theta_fixed/DF_theta)
  } else {

    if (contemporaneous == "randomGGM"){
      Theta <- lapply(1:nPerson,function(x){
        net <- simGraph(nNode,GGMsparsity)
        cov2cor(solve(diag(nNode) - net))
      })
      Theta <- do.call(abind,c(Theta,along=3))
     
      Theta_fixed <- apply(Theta,1:2,mean)
    } else {
      net <- simGraph(nNode,GGMsparsity)
      Theta_fixed <- cov2cor(solve(diag(nNode) - net))
      Theta <- lapply(1:nPerson,function(x)Theta_fixed)
      Theta <- do.call(abind,c(Theta,along=3))
    }
  }
 
  # if no empirical model is provided
  if(is.null(empirical_model)){
  # Generate fixed means:
  mu_fixed <- rnorm(nNode,0,fixedMuSD)
  # Generate fixed betas:
  beta_fixed <- rnorm(nTemporal,0, fixedBetaSD)
  # set weakest beta_sparsity% to zero:
  beta_fixed[order(abs(beta_fixed))[1:round(nTemporal * beta_sparsity)]] <- 0
  
  # Include auto-regressions:
  mat <- matrix(0,nNode,nNode*lag)
  diag(mat) <- 1
  beta_fixed[c(mat)==1] <- runif(sum(c(mat)==1),0,1)
  }
  # If empirical model is provided for fixed effects
  if(!is.null(empirical_model)){
    mu_fixed <- empirical_model$results$mu$mean
    beta_fixed <- empirical_model$results$Beta$mean
  }
  
  
  # 3. Generate random parameter sets:
  if (lag > 0){
    try <- 1 
    maxtry <- 5000
    repeat{
      Pars <- rmvnorm(nPerson, c(mu_fixed,beta_fixed), sigma = Omega)
      Mus <- Pars[,1:nNode]
      
      Betas <- array(c(t(Pars[,-(1:nNode)])), c(nNode,nNode*lag,nPerson))
      
      # 4. Construct the matrices:
      if (lag>1){
        under <- cbind(diag(nNode*(lag-1)),matrix(0,nNode*(lag-1),nNode))
        
        ev <- sapply(seq_len(nPerson),function(i){
          mat <- rbind(Betas[,,i],under)
          eigen(mat)$values
        })
        
      } else {
        
        ev <- sapply(seq_len(nPerson),function(i){
          eigen(Betas[,,i])$values
        })
        
      }
      # 5. Store results:
      allEV <- c(ev)
      
      # 6. Break if all Re(ev)^2 + Im(ev)^2 < 1
      if (all(Re(ev)^2 + Im(ev)^2 < 1)){
        
        # simulate VAR for every person:
        DataList <- lapply(1:nPerson,function(p){
          
          pars <- lapply(seq_len(lag),function(l)array(c(Betas[,,p]),c(nNode,nNode,lag))[,,l])
          # If lag > 0 simulate VAR:
          if (lag > 0){
            res <- mlVAR::simulateVAR(pars, 
                                      means = Mus[p,], 
                                      lags = seq_len(lag), 
                                      Nt = nTime[p],
                                      init = Mus[p,],
                                      burnin = 100,
                                      residuals = Theta[,,p]) 
          } else {
            res <- rmvnorm(nTime[p],Mus[p,],Theta[,,p])
          }
          colnames(res) <- paste0("V",1:nNode)
          res$ID <- p
          res
        })
        
        # Rbind data:
        Data <- do.call(rbind,DataList)
        
        # 10. If any absolute > 100, go to 6a
        if (!any(abs(Data[,1:nNode]) > 100)){
          break
        }
      } 
      
      # Else shrink:
      beta_fixed <- beta_fixed * shrink_fixed
      D <- diag(sqrt(diag(Omega)))
      D[-(1:nNode),-(1:nNode)] <- shrink_deviation * D[-(1:nNode),-(1:nNode)] 
      Omega <- D %*% cov2cor(Omega) %*% D
    
      try <- try + 1
      if (try > maxtry){
        stop("Maximum number of tries reached.")
      }
    }
  }
    else {   # if lag = 0
    Pars <- rmvnorm(nPerson, mu_fixed, sigma = Omega)
    Mus <- Pars[,1:nNode]
    Betas <- array(dim = c(0,0,nPerson))
    
    # simulate VAR for every person:
    DataList <- lapply(1:nPerson,function(p){
      res <- as.data.frame(rmvnorm(nTime[p],Mus[p,],Theta[,,p]))
      colnames(res) <- paste0("V",1:nNode)
      res$ID <- p
      res
    })
    
    # Rbind data:
    Data <- do.call(rbind,DataList)
    
  }
  
  
  # Create the list:
  model <- list(
    mu = mlVAR:::modelArray(mean = mu_fixed, 
                            SD = mu_SD, 
                            subject = lapply(1:nrow(Mus), function(i)Mus[i,])),
    Beta = mlVAR:::modelArray(mean = array(beta_fixed,c(nNode,nNode,lag)), 
                              SD = array(sqrt(diag(Omega[-(1:nNode),-(1:nNode)])),c(nNode,nNode,lag)), 
                              subject = lapply(1:nPerson, 
                                               function(p)
                                                 array(Betas[,,p],c(nNode,nNode,lag)))),
    Omega_mu = mlVAR:::modelCov(
      cov = mlVAR:::modelArray(mean = Omega[1:nNode,1:nNode])
    ),
    Theta = mlVAR:::modelCov(
      cov = mlVAR:::modelArray(mean = Theta_fixed, 
                               subject = lapply(1:nPerson,function(p)Theta[,,p]))
    ),
    Omega = mlVAR:::modelCov(
      cov = mlVAR:::modelArray(mean = Omega)
    )
    
  )
  
  
  # Data generated! Now return in sensible list:
  Results <- list(
    Data = Data,
    vars = paste0("V",1:nNode),
    idvar = "ID",
    lag=lag,
    try = try,
model=model
  )
  
  class(Results) <- "mlVARsim"
  
  return(Results)
}


```


## Test mlVARsim_mod

```{r}
set.seed(123)
sim <- mlVARsim_mod(nPerson = 100, 
                    nNode = 9, 
                    nTime = 200, 
                    empirical_model = res3,
                    init_beta_SD = c(.1,4),
                    mu_SD = c(.1, .3),
                    shrink_deviation = 0.999,
                    fixedMuSD = 0.3,
                    fixedBetaSD = 1, 
                    pcor_sparsity = 0,
                    beta_sparsity = 0
                    # DF_theta = 1*6
                    )

sim_old <- mlVAR::mlVARsim(nPerson = 100, 
                    nNode = 6, 
                    nTime = 100, 
                    init_beta_SD = c(2,2)
                    )

```

Investigate heterogeneity of individual networks. Simulating with more heterogeneity does not really work. It seems like for the betas, only every second column is affected.

```{r}
ml_beta <- sim$model$Beta$subject
ml_pcor <- sim$model$Theta$pcor$subject

# across all matrices in the list, compute the element-wise sd
sd_beta <- sim$model$Beta$SD
sd_pcor <- sim$model$Theta$pcor$SD

# these are the empirical values
apply(simplify2array(ml_beta), c(1,2), sd)
apply(simplify2array(ml_pcor), c(1,2), sd)


# These are the simulation values
sd_beta
sd_pcor
```


# Trying simMLgvar

```{r}
library(graphicalVAR)
set.seed(2024)
sim_mlgvar <- simMLgvar(
                       nTime = 150, 
                       nVar = 6, 
                       nPerson = 200, 
                       propPositive = 0.5, 
                       kappaRange = c(0.25, 0.5),
                       betaRange = c(0.25, 0.5), 
                       betweenRange = c(0.25, 0.5),
                       rewireWithin = 0, 
                       betweenVar = 1, 
                       withinVar = 0.25,
                       temporalOffset = 2)

```
This does not look nice - cannot modify as much as I would like to. 




# Fit model on empirical data
Here, I use code by Mansueto et al. (2022) to obtain the mlVAR network and extract coefficients to simulate from. 
It's based on https://osf.io/7fpw5, data can be obtained from https://osf.io/5a2ub. Same code was used in Siepe, Kloft & Heck (2024).

### Preparation
```{r}
set.seed(35037)
library(lme4)
library(mlVAR)
library(lm.beta)
load(here::here("data/clean_network.RData"))
Data5b <- Data2

# Alpha to detrend:
alpha <- 0.05

# Variables to investigate:
vars <- c("Q1","Q2","Q3","Q4","Q5","Q6","Q7","Q8","Q9","Q10","Q11","Q12","Q13","Q14","Q15","Q16","Q17","Q18")

# Labels:
varLabs <- c("Relax","Irritable","Worry","Nervous","Future","Anhedonia",
             "Tired","Hungry","Alone","Angry","Social_offline","Social_online","Music",
             "Procrastinate","Outdoors","C19_occupied","C19_worry","Home")


names(Data5b)[names(Data5b) %in% vars] <- varLabs

# Remove items:
Data5b <- Data5b %>% 
  dplyr::select(!c(Hungry,Angry,Music,Procrastinate))
varLabs <- varLabs[!varLabs %in% c("Hungry","Angry","Music","Procrastinate")]

# Data frame with empty values for fitted effects (all):
fitted_all <- expand.grid(
  beep = seq(min(Data5b$beep),max(Data5b$beep)),
  day = seq(min(Data5b$day),max(Data5b$day))
)

# Data frame with empty values for day trends:
fitted_day <- data.frame(
  day = seq(min(Data5b$day),max(Data5b$day))
)

# Data frame with empty values for beeps:
fitted_beep <- data.frame(
  beep = seq(min(Data5b$beep),max(Data5b$beep))
)

# Data frame to store p-values:
p_values <- data.frame(
  var = c("day", "beep")
)

# Also empty data frame list for test statistics:
testStatistics <- list()
coefficients <- list()
stdcoefficients <- list()

# Make the beep variable factor in dataset:
Data5b$beepFactor <- factor(Data5b$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))
fitted_all$beepFactor <- factor(fitted_all$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))
fitted_beep$beepFactor <- factor(fitted_beep$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))

# Make day variable for dates:
Data5b$date <- as.Date("2020-03-15") + Data5b$day
fitted_all$date <- as.Date("2020-03-15") + fitted_all$day
fitted_day$date <- as.Date("2020-03-15") + fitted_day$day

# Add the midpoints as time variable:
Data5b$midTime <- as.character(factor(Data5b$beep, levels = 0:3, labels = c("10:30","13:30","16:30","19:30")))
Data5b$midTime <- as.POSIXct(paste(Data5b$date,Data5b$midTime), format = "%Y-%m-%d %H:%M", tz = "Europe/Amsterdam")

fitted_all$midTime <- as.character(factor(fitted_all$beep, levels = 0:3, labels = c("10:30","13:30","16:30","19:30")))
fitted_all$midTime <- as.POSIXct(paste(fitted_all$date,fitted_all$midTime), format = "%Y-%m-%d %H:%M", tz = "Europe/Amsterdam")

# Data frame to store detrended data:
data_detrended <- Data5b

# Fix curves:
for (v in seq_along(varLabs)){
  formula <- as.formula(paste0(varLabs[v], " ~ 1 + day + factor(beep)")) #why 1? With or without 1 results seem to be the same
  lmRes <- lm(formula, data = Data5b)
  
  # Fixed effects:
  fixed <- coef(lmRes)
  
  # make zero if not significant at alpha:
  p_values[[varLabs[v]]] <- anova(lmRes)[["Pr(>F)"]][1:2]
  if (p_values[[varLabs[v]]][1] > alpha){
    fixed[2] <- 0
  }
  if (p_values[[varLabs[v]]][2] > alpha){
    fixed[3:5] <- 0
  }
  
  # Add to DFs:
  fitted_all[,varLabs[v]] <- fixed[1] + fixed[2] * fitted_all[["day"]]  +  fixed[3] * (fitted_all[["beep"]] == 1)  + 
  fixed[4] * (fitted_all[["beep"]] == 2) + fixed[5] *  (fitted_all[["beep"]] == 3)
  
  fitted_day[,varLabs[v]] <- fixed[1] + fixed[2] * fitted_day[["day"]]
  
  fitted_beep[,varLabs[v]] <- fixed[1] + fixed[2] * median(fitted_day[["day"]]) +  fixed[3] * (fitted_beep[["beep"]] == 1)  + 
    fixed[4] * (fitted_beep[["beep"]] == 2) + fixed[5] *  (fitted_beep[["beep"]] == 3)
  
  # Detrend data:
  data_detrended[,varLabs[v]] <- Data5b[,varLabs[v]] - (fixed[1] + fixed[2] * Data5b[["day"]]  +  fixed[3] * (Data5b[["beep"]] == 1)  + 
    fixed[4] * (Data5b[["beep"]] == 2) + fixed[5] *  (Data5b[["beep"]] == 3))
  
  # Test statistic dataframe:
  ids <- rownames(anova(lmRes))
  testStatistics[[v]] <- cbind(data.frame(var = varLabs[v], effect = ids), anova(lmRes))
  
  coefficients[[v]] <- data.frame(
    var = varLabs[v],
    type = names(coef(lmRes)),
    coef = coef(lmRes),
    std = coef(lm.beta(lmRes))
  )
}


```

### Fitting
```{r}
data_detrended$Anxiety <- rowMeans(dplyr::select(data_detrended, Irritable, Worry, Nervous, Relax), na.rm = FALSE)
data_detrended$Depression <- rowMeans(dplyr::select(data_detrended, Anhedonia, Future, Tired), na.rm = FALSE)

varLabs6 <- c("Anxiety", "Depression", "Alone","Social_offline","Social_online",
             "Outdoors")

# Run mlVAR (correlated):
res6 <- mlVAR(data_detrended,
              vars=varLabs6,
              idvar="id",
              dayvar="day",
              beepvar="beep",
              lags = 1,
              temporal = "correlated",
              contemporaneous = "correlated",
              nCores = 13)

# # # delete irrelevant data storage
# res3 <- res3[res3!="data"]
saveRDS(res6, here("data/network_fried2020_6n.RData"))
# # load model
# res3<-readRDS(here("data/network_fried2020_9n.RData"))

# Names for the Plot :
names <- c("Anxiety", "Depression", "Alone", 
            "Social Offline", "Social Online", "Outdoors",
            "C19 Occupied", "C19 Worry", "Home") 

# Get the contemporaneous and temporal networks:
cont6 <- getNet(res6, "contemporaneous", layout = "spring", nonsig = "hide", rule = "and")
#bet6 <- getNet(res3, "between", nonsig = "hide", rule = "and")
temp6 <- getNet(res6, "temporal", nonsig = "hide")


```

Create sparse graph (see https://github.com/bsiepe/var-compare/blob/main/true-networks.Rmd)
```{r}
# beta 
beta_6n <- res6$results$Beta$mean[,,1] * t(temp6 != 0)

# partial correlations
omega_6n <- res6$results$Theta$pcor$mean * (cont6 != 0)

# precision matrix
theta_6n <- res6$results$Theta$prec$mean * (cont6 != 0 | diag(ncol(cont6)) == 1)

graph_sparse <- list(beta = beta_6n, pcor = omega_6n, kappa = theta_6n)
saveRDS(graph_sparse, here("data/graph_sparse.RDS"))

```

Create nonsparse graph
```{r}
beta_6n <- res6$results$Beta$mean[,,1]
omega_6n <- res6$results$Theta$pcor$mean
theta_6n <- res6$results$Theta$prec$mean
graph_nonsparse <- list(beta = beta_6n, pcor = omega_6n, kappa = theta_6n)
saveRDS(graph_nonsparse, here("data/graph_nonsparse.RDS"))

```



# Writing own function
Try to create a function that uses a fitted fixed-effects structure to simulate data with a specific random effects variance, but uses a graphicalVAR structure for each individual.
Taken from here: https://github.com/bsiepe/var-compare/blob/main/true-networks.Rmd

```{r}
# Graph to simulate from
graph_nonsparse <- readRDS(here("data/graph_nonsparse.RDS"))
graph_sparse <- readRDS(here("data/graph_sparse.RDS"))
```

This function should:
1. Take the fixed effects structure for beta and kappa
2. Create random effects for beta and for kappa 
3. Simulate data for each individual using the graphicalVAR 


```{r}
sim_gvar <- function(graph,
                     beta_sd,
                     kappa_sd,
                     n_person,
                     n_time,
                     n_node,
                     max_try = 1000){
  # browser()
  
  # Create a list to store the data for each person
  data <- vector("list", n_person)
  
  
  counter <- 0
    repeat {
      counter <- counter + 1
      if(counter > max_try) stop("Exceeded maximum number of attempts to generate stable beta matrix.")
      
      # Generate beta matrix using graph$beta as mean
      beta <- array(rnorm(n_node*n_node*n_person, mean = graph$beta, sd = beta_sd), c(n_node, n_node, n_person))
      
      # Check if beta matrix is stable
      ev_b <- sapply(seq_len(n_person),function(i){
          eigen(beta[,,i])$values
        })
      if(all(Re(ev_b)^2 + Im(ev_b)^2 < 1)) break
      
    }
    
    counter <- 0
    repeat {
      counter <- counter + 1
      if(counter > max_try) stop("Exceeded maximum number of attempts to generate semi-positive definite kappa matrix.")
      
      # Generate kappa matrix using graph$kappa as mean
      kappa <- array(rnorm(n_node*n_node*n_person, mean = graph$kappa, sd = kappa_sd), c(n_node, n_node, n_person))
      
      # Make kappa matrix symmetric
      # but keep as array
      force_symmetric <- function(mat) {
              as.matrix(Matrix::forceSymmetric(mat))
          }
      
      kappa <- array(apply(kappa, MARGIN = 3, FUN = force_symmetric), dim = dim(kappa)) 
      
      # Check if kappa matrix is semi-positive definite
      ev_k <- sapply(seq_len(n_person),function(i){
          eigen(kappa[,,i])$values
        })
      
      if(all(ev_k >= 0)) break
    }
    
    # Simulate data for each person
    for(i in seq_len(n_person)){
    data[[i]] <- tryCatch({graphicalVAR::graphicalVARsim(nTime = n_time,
                                               beta = beta[,,i],
                                               kappa = kappa[,,i]
                                               )}, error = function(e) NA)
    }
  
  
  # Return the list of simulated data
  # Also return the parameters used in the simulation
  ret <- list()
  ret$data <- data
  ret$beta <- beta
  ret$kappa <- kappa
  return(ret)

}
```

Try the function
```{r}
sim_data <- sim_gvar(graph = graph_nonsparse,
                     beta_sd = 0.1,
                     kappa_sd = 0.1,
                     n_person = 100,
                     n_time = 150,
                     n_node = 6,
                     max_try = 10000)
```

This still does not work with a larger amount of beta sd



## With for-loop approach

Idea: In the function above (`sim_gvar`), all beta and kappa matrices are generated at once.Instead, we could generate the beta and kappa matrices for each individual separately. This would allow us to check for stability and semi-positive definiteness for each individual separately. 



Try the function
```{r}
sim_data_loop <- sim_gvar_loop(
                     graph = graph_sparse,
                     beta_sd = 0.75,
                     kappa_sd = 0.3,
                     n_person = 100,
                     n_time = 150,
                     n_node = 6,
                     max_try = 10000,
                     sparse_sim = TRUE)

```

Try if it can be fitted
```{r}
data_loop <- sim_data_loop$data %>% 
  # convert each array in list to dataframe
  map(~as.data.frame(.x)) %>%
  bind_rows(.id = "id") 
  
var_labs <- c("V1", "V2", "V3", "V4", "V5", "V6")


loop_test_fit <- mlVAR(data_loop,
              vars=var_labs,
              idvar="id",
              lags = 1,
              temporal = "correlated",
              contemporaneous = "correlated",
              nCores = 13)
```


Check if it actually increases the random effects sd as intended

```{r}
# non-sparse Graph to simulate from
graph_nonsparse <- readRDS(here::here("data/graph_nonsparse.RDS"))

# sparse DGP
graph_sparse <- readRDS(here::here("data/graph_sparse.RDS"))

dgp <- "sparse"
heterogeneity <- "low"
heterogeneity <- "high"

dgp_graph <- ifelse(dgp == "sparse", 
                      "graph_sparse", 
                      "graph_nonsparse")
beta_sd <- ifelse(heterogeneity == "low",
                    0.05,
                    0.1)
  
n_id <- 50 
n_tp <- 75
n_var <- 6

# scale kappa random effects w.r.t diagonal elements
mean_diag_kappa <- mean(diag(graph_sparse$kappa)) 
kappa_sd_low <- 0.05 * mean_diag_kappa
kappa_sd_high <- 0.1 * mean_diag_kappa
  
kappa_sd <- ifelse(heterogeneity == "low",
                     kappa_sd_low,
                     kappa_sd_high)
  
ml_sim <- sim_gvar_loop(
                     graph = graph_sparse,
                     beta_sd = beta_sd,
                     kappa_sd = kappa_sd,
                     n_person = n_id,
                     n_time = n_tp,
                     n_node = n_var,
                     max_try = 10000,
                     listify = TRUE,
                     sparse_sim = TRUE)

# Check if the beta and kappa sd are as intended
ml_sim$beta %>% 
  apply(c(1,2), sd) %>% 
  mean()

ml_sim$pcor %>% 
  apply(c(1,2), sd) %>% 
  # remove diagonal 
  .[upper.tri(.)] %>% 
  mean()




```




## Try GIMME model fit 
Try it out to see how best to extract results
```{r}
gimme_fit <- gimme::gimme(ml_sim$data,
             ar = TRUE,
             subgroup = TRUE,
             plot = TRUE,
             hybrid = FALSE,
             VAR = TRUE,
             groupcutoff = .75,
             subcutoff = .75)

gimme_fit$path_se_est |> 
  # filter contemporaneous relationships
  filter(op == "~~") |>
  filter(pval < 0.05) |>
  mutate(file = str_remove(file, "subj")) %>% 
  filter(file == 1) %>% 
  select(lhs, rhs, beta.std) %>% 
  spread(lhs, beta.std) %>% 
  column_to_rownames(var = "rhs") %>%
  as.matrix()









centrality_gimme <- function(fit,
                             var_only = FALSE){  # only covariances in contemp?
  
  #--- Prepare 
  n_var <- fit$n_vars_total
  temp_ind <- 1:(n_var/2)
  cont_ind <- ((n_var/2)+1):n_var
  
  
  #--- Density
  dens_temp <- lapply(fit$path_est_mats, function(x){
    if(!is.double(x)){
      NA
    }
    else{
      sum(abs(x[, temp_ind]))/(n_var^2)
    }
  })
  
  dens_cont <- lapply(fit$path_est_mats, function(x){
    if(!is.double(x)){
      NA
    }
    else{
      x <- x[, cont_ind]
      diag(x) <- 0
      x[lower.tri(x)] <- 0L
      sum(abs(x))/ (n_var * (n_var-1)/2)
    }
  })

  #--- Centrality
  outstrength <- lapply(fit$path_est_mats, function(x){
    if(!is.double(x)){
      NA
    }
    else{
      colSums(abs(x[, temp_ind]))/n_var
    }
  })
  instrength <- lapply(fit$path_est_mats, function(x){
    if(!is.double(x)){
      NA
    }
    else{
      rowSums(abs(x[, temp_ind]))/n_var
    }
  })
  strength <- lapply(fit$path_est_mats, function(x){
    if(!is.double(x)){
      NA
    }
    else{
      # x <- x[, cont_ind]
      # diag(x) <- 0
      # x[lower.tri(x)] <- 0L
      colSums(abs(x))/n_var
    }
  })
  
  # return list
  return(list(outstrength = outstrength,
              instrength = instrength,
              strength = strength,
              dens_temp = dens_temp,
              dens_cont = dens_cont))
  
  
}

```



