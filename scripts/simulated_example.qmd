---
title: "Simulated Example"
format: html
---

# Idea & Preparation
In this script, we will simulate a dataset of individual time series, and a time-invariant covariate.
We will then fit (graphical)VAR models and a regression of centrality/density with the covariate.

```{r packages}
library(tidyverse)
library(graphicalVAR)
library(mlVAR)
library(parallel)
library(here)
library(broom)
library(gimme)
library(cmdstanr)
set.seed(35037)
source(here("scripts", "functions.R"))

```

# Simulate data

## Simulate time series data with specific centrality/density
We simulate data from a multilevel model for now.

```{r sim-params}
n <- 50
nvar <- 6
tp <- 100

```


TODO: The following does not work yet when we scale the variables, because the true values are not scaled. Maybe we can just not scale the variables for LASSO, because the variances will be roughly equal anyway.

Alternatively, I could just use the simulated matrices to again simulate graphicalVAR data. This would solve the issue. 
```{r sim-data}
# Simulate data
ml_sim <- mlVAR::mlVARsim(nPerson = n, 
                nNode = nvar, 
                nTime = tp, 
                lag = 1, 
                thetaVar = rep(1,nvar),
                DF_theta = nvar * 2, 
                mu_SD = c(1, 1), 
                init_beta_SD = c(0.1, 1), 
                fixedMuSD = 1, 
                shrink_fixed = 0.9, 
                shrink_deviation = 0.9)

# Obtain individual models and data
ml_data <- ml_sim$Data %>%
  group_by(ID) %>% 
  # mutate(across(c(V1, V2, V3, V4, V5, V6), ~scale(.))) %>%
  ungroup() %>% 
  split(.$ID)

# Obtain parameters
ml_beta <- ml_sim$model$Beta$subject
ml_prec <- ml_sim$model$Theta$prec$subject
ml_pcor <- ml_sim$model$Theta$pcor$subject


# Obtain centrality and density
# TODO double check the matrix formatting here
# where are the DVs, where is the IV
ml_outstrength <- lapply(ml_beta, function(x){colSums(abs(x))})
ml_instrength <- lapply(ml_beta, function(x){rowSums(abs(x))})
ml_strength <- lapply(ml_pcor, function(x){
  diag(x) <- 0
  x[lower.tri(x)] <- 0L
  colSums(abs(x))
})
ml_temporal_density <- lapply(ml_beta, function(x)sum(abs(x)))
# This should be equivalent to strength
ml_contemporaneous_density <- lapply(ml_pcor, function(x){
  diag(x) <- 0
  x[lower.tri(x)] <- 0L
  sum(abs(x))
})

```



## Simulate regression data
Simulate data from simple one-predictor regression model:
```{r sim-covariate}
# Extract temporal density as predictor
tempdens <- unlist(ml_temporal_density)

# Simulate linear model data with regression coefficient of 0.5
eps <- 1

# Simulate error
resid <- rnorm(n, mean = 0, sd = eps)

reg_data <- tibble(
  ID = 1:n,
  tempdens = tempdens,
  depression = 0.25 * tempdens + resid
) 

```

# Fit models

## Fit time series models

### graphicalVAR
Fit graphicalVAR model to each time series:
```{r fit-graphicalvar}
# setup cluster
cl <- parallel::makeCluster(parallel::detectCores() - 8)
parallel::clusterEvalQ(cl, {
  library(graphicalVAR)
})

# Fit idiograpgic gVAR
ml_fit <- parallel::parLapply(cl, ml_data, function(x){
  graphicalVAR::graphicalVAR(x)
})

parallel::stopCluster(cl)

```


### GIMME
Fit GIMME model to all time series: 
```{r fit-gimme}
gimme_data <- lapply(ml_data, function(x){x[,-7]})

gimme_fit <- gimme::gimme(data = gimme_data,
                          subgroup = TRUE)



```






### Stan
Prepare Stan model 
```{r}
# Combine data to data.frame
Y <- do.call(rbind, ml_data)
# Remove ID column
Y <- Y[, -7]


# Obtain dimensions
K <- ncol(Y) 
NR <- nrow(Y)
n_t <- rep(tp, n)

# Prep stan data
stan_data <-
  list(K = K,
       I = I,
       N = NR,
       n_t = n_t,
       Y = as.array(as.matrix(Y))
  )
# Choose model to fit
model_name <- "VAR_LKJ_centrality"
# Compile model
var_lkj_model <- cmdstanr::cmdstan_model(
  stan_file = here("scripts", paste0(model_name, ".stan")),
  pedantic = TRUE#, 
  #quiet = FALSE
  )

```

Now fit the model (takes ages):
```{r}
n_chains <- 4
# Run sampler
var_lkj_fit <- var_lkj_model$sample(
  data = stan_data,
  seed = 2023,
  chains = n_chains,
  parallel_chains = n_chains,
  iter_warmup = 500,
  iter_sampling = 500,
  refresh = 500,
  thin = 1,
  adapt_delta = .8,
  init = .1
)
# time to fit
var_lkj_fit$time()$total
```




## Fit regression model

### Extract centralities

```{r}
emp_centrality <- lapply(ml_fit, centrality_graphicalvar)

```

Compare to true centralities
```{r}
tempdens_true <- unlist(ml_tempdens)
tempdens_emp <- unlist(lapply(emp_centrality, function(x) x$dens_temp))
reg_data <- reg_data %>%
  mutate(
    tempdens_emp = tempdens_emp
  )
```



### Fit model
Fit the regression model 
```{r}
# Attach estimated centralities to the dataframe: 
reg_fit <- reg_data %>% 
  do(tidy(lm(depression ~ tempdens_emp, data = .)))

```

Visualize the result with the true values. 
```{r}
# Visualize the result
reg_data %>% 
  pivot_longer(cols = c(tempdens, tempdens_emp), 
               names_to = "type", 
               values_to = "tempdens") %>%
  ggplot(aes(x = tempdens, y = depression, color = type)) +
  geom_point() +
  geom_abline(intercept = reg_fit$estimate[1], 
              slope = reg_fit$estimate[2]) +
  theme_minimal()+
  theme(legend.position = "none")+
  # add true slope
  geom_abline(intercept = 0, slope = 0.5, linetype = "dashed")+
  # add numeric values of slopes in the figure
  annotate("text", x = 2, y = 0.5, label = paste0("True slope: ", 0.5))+
  annotate("text", x = 2, y = 0.2, label = paste0("Estimated slope: ", round(reg_fit$estimate[2], 2)))

```








