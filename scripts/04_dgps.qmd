---
title: "Centrality Uncertainty"
subtitle: "Data-Generating Processes"
format: html
---

# Preparation

```{r}
library(tidyverse)
library(lme4)
library(mlVAR)
library(lm.beta)
library(mnet)  # for the Koval data
library(here)
set.seed(35037)
```





# Fit model on empirical data by Fried et al.
Here, I use code by Mansueto et al. (2022) to obtain the mlVAR network and extract coefficients to simulate from. 
It's based on https://osf.io/7fpw5, data can be obtained from https://osf.io/5a2ub. Same code was used in Siepe, Kloft & Heck (2024).

### Preparation
```{r}
load(here::here("data/clean_network.RData"))
Data5b <- Data2

# Alpha to detrend:
alpha <- 0.05

# Variables to investigate:
vars <- c("Q1","Q2","Q3","Q4","Q5","Q6","Q7","Q8","Q9","Q10","Q11","Q12","Q13","Q14","Q15","Q16","Q17","Q18")

# Labels:
varLabs <- c("Relax","Irritable","Worry","Nervous","Future","Anhedonia",
             "Tired","Hungry","Alone","Angry","Social_offline","Social_online","Music",
             "Procrastinate","Outdoors","C19_occupied","C19_worry","Home")


names(Data5b)[names(Data5b) %in% vars] <- varLabs

# Remove items:
Data5b <- Data5b %>% 
  dplyr::select(!c(Hungry,Angry,Music,Procrastinate))
varLabs <- varLabs[!varLabs %in% c("Hungry","Angry","Music","Procrastinate")]

# Data frame with empty values for fitted effects (all):
fitted_all <- expand.grid(
  beep = seq(min(Data5b$beep),max(Data5b$beep)),
  day = seq(min(Data5b$day),max(Data5b$day))
)

# Data frame with empty values for day trends:
fitted_day <- data.frame(
  day = seq(min(Data5b$day),max(Data5b$day))
)

# Data frame with empty values for beeps:
fitted_beep <- data.frame(
  beep = seq(min(Data5b$beep),max(Data5b$beep))
)

# Data frame to store p-values:
p_values <- data.frame(
  var = c("day", "beep")
)

# Also empty data frame list for test statistics:
testStatistics <- list()
coefficients <- list()
stdcoefficients <- list()

# Make the beep variable factor in dataset:
Data5b$beepFactor <- factor(Data5b$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))
fitted_all$beepFactor <- factor(fitted_all$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))
fitted_beep$beepFactor <- factor(fitted_beep$beep, levels = 0:3, labels = c("09:00 - 12:00","12:00 - 15:00","15:00 - 18:00","18:00 - 21:00"))

# Make day variable for dates:
Data5b$date <- as.Date("2020-03-15") + Data5b$day
fitted_all$date <- as.Date("2020-03-15") + fitted_all$day
fitted_day$date <- as.Date("2020-03-15") + fitted_day$day

# Add the midpoints as time variable:
Data5b$midTime <- as.character(factor(Data5b$beep, levels = 0:3, labels = c("10:30","13:30","16:30","19:30")))
Data5b$midTime <- as.POSIXct(paste(Data5b$date,Data5b$midTime), format = "%Y-%m-%d %H:%M", tz = "Europe/Amsterdam")

fitted_all$midTime <- as.character(factor(fitted_all$beep, levels = 0:3, labels = c("10:30","13:30","16:30","19:30")))
fitted_all$midTime <- as.POSIXct(paste(fitted_all$date,fitted_all$midTime), format = "%Y-%m-%d %H:%M", tz = "Europe/Amsterdam")

# Data frame to store detrended data:
data_detrended <- Data5b

# Fix curves:
for (v in seq_along(varLabs)){
  formula <- as.formula(paste0(varLabs[v], " ~ 1 + day + factor(beep)")) #why 1? With or without 1 results seem to be the same
  lmRes <- lm(formula, data = Data5b)
  
  # Fixed effects:
  fixed <- coef(lmRes)
  
  # make zero if not significant at alpha:
  p_values[[varLabs[v]]] <- anova(lmRes)[["Pr(>F)"]][1:2]
  if (p_values[[varLabs[v]]][1] > alpha){
    fixed[2] <- 0
  }
  if (p_values[[varLabs[v]]][2] > alpha){
    fixed[3:5] <- 0
  }
  
  # Add to DFs:
  fitted_all[,varLabs[v]] <- fixed[1] + fixed[2] * fitted_all[["day"]]  +  fixed[3] * (fitted_all[["beep"]] == 1)  + 
  fixed[4] * (fitted_all[["beep"]] == 2) + fixed[5] *  (fitted_all[["beep"]] == 3)
  
  fitted_day[,varLabs[v]] <- fixed[1] + fixed[2] * fitted_day[["day"]]
  
  fitted_beep[,varLabs[v]] <- fixed[1] + fixed[2] * median(fitted_day[["day"]]) +  fixed[3] * (fitted_beep[["beep"]] == 1)  + 
    fixed[4] * (fitted_beep[["beep"]] == 2) + fixed[5] *  (fitted_beep[["beep"]] == 3)
  
  # Detrend data:
  data_detrended[,varLabs[v]] <- Data5b[,varLabs[v]] - (fixed[1] + fixed[2] * Data5b[["day"]]  +  fixed[3] * (Data5b[["beep"]] == 1)  + 
    fixed[4] * (Data5b[["beep"]] == 2) + fixed[5] *  (Data5b[["beep"]] == 3))
  
  # Test statistic dataframe:
  ids <- rownames(anova(lmRes))
  testStatistics[[v]] <- cbind(data.frame(var = varLabs[v], effect = ids), anova(lmRes))
  
  coefficients[[v]] <- data.frame(
    var = varLabs[v],
    type = names(coef(lmRes)),
    coef = coef(lmRes),
    std = coef(lm.beta(lmRes))
  )
}


```

### Fitting
```{r}
data_detrended$Anxiety <- rowMeans(dplyr::select(data_detrended, Irritable, Worry, Nervous, Relax), na.rm = FALSE)
data_detrended$Depression <- rowMeans(dplyr::select(data_detrended, Anhedonia, Future, Tired), na.rm = FALSE)

varLabs6 <- c("Anxiety", "Depression", "Alone","Social_offline","Social_online",
             "Outdoors")

# Run mlVAR (correlated):
res6 <- mlVAR(data_detrended,
              vars=varLabs6,
              idvar="id",
              dayvar="day",
              beepvar="beep",
              lags = 1,
              temporal = "correlated",
              contemporaneous = "correlated",
              nCores = 13)

# # # delete irrelevant data storage
# res3 <- res3[res3!="data"]
saveRDS(res6, here("data/network_fried2020_6n.RData"))
# # load model
# res3<-readRDS(here("data/network_fried2020_9n.RData"))

# Names for the Plot :
names <- c("Anxiety", "Depression", "Alone", 
            "Social Offline", "Social Online", "Outdoors",
            "C19 Occupied", "C19 Worry", "Home") 

# Get the contemporaneous and temporal networks:
cont6 <- getNet(res6, "contemporaneous", layout = "spring", nonsig = "hide", rule = "and")
#bet6 <- getNet(res3, "between", nonsig = "hide", rule = "and")
temp6 <- getNet(res6, "temporal", nonsig = "hide")


```

Create sparse graph (see https://github.com/bsiepe/var-compare/blob/main/true-networks.Rmd)
```{r}
# beta 
beta_6n <- res6$results$Beta$mean[,,1] * t(temp6 != 0)

# partial correlations
omega_6n <- res6$results$Theta$pcor$mean * (cont6 != 0)

# precision matrix
theta_6n <- res6$results$Theta$prec$mean * (cont6 != 0 | diag(ncol(cont6)) == 1)

graph_sparse <- list(beta = beta_6n, pcor = omega_6n, kappa = theta_6n)
saveRDS(graph_sparse, here("data/graph_sparse.RDS"))

```

Create nonsparse graph
```{r}
beta_6n <- res6$results$Beta$mean[,,1]
omega_6n <- res6$results$Theta$pcor$mean
theta_6n <- res6$results$Theta$prec$mean
graph_nonsparse <- list(beta = beta_6n, pcor = omega_6n, kappa = theta_6n)
saveRDS(graph_nonsparse, here("data/graph_nonsparse.RDS"))
```




# Fit model to data by Koval et al. 

We now fit the model to the data by Koval et al. (2013). These data have been used in previous publications, such as https://doi.org/10.31234/osf.io/dhp8s. They are included in the `mnet` package. We fit the model as in the publication by Haslbeck et al. by adapting [this](https://github.com/jmbh/mlVARGD/blob/main/Tutorial/Tutorial_Koval13.R) code. 
 
```{r}
data("dataKoval13")

koval_fit <- mlVAR(data = dataKoval13,
                vars = colnames(dataKoval13)[7:12],
                idvar = "PID",
                dayvar = "UNIT",
                beepvar = "OCCASION",
                contemporaneous = "correlated",
                temporal = "correlated")


```

We can then obtain a sparse and a nonsparse network from this fit: 
```{r}
# Get the contemporaneous and temporal networks:
cont_koval <- getNet(koval_fit, "contemporaneous", nonsig = "hide", rule = "and")
temp_koval <- getNet(koval_fit, "temporal", nonsig = "hide")

# Sparse network
beta_koval <- koval_fit$results$Beta$mean[,,1] * t(temp_koval != 0)
omega_koval <- koval_fit$results$Theta$pcor$mean * (cont_koval != 0)
theta_koval <- koval_fit$results$Theta$prec$mean * (cont_koval != 0 | diag(ncol(cont_koval)) == 1)
graph_sparse_koval <- list(beta = beta_koval, pcor = omega_koval, kappa = theta_koval)
saveRDS(graph_sparse_koval, here("data/graph_sparse_koval.RDS"))

# Nonsparse network
beta_koval <- koval_fit$results$Beta$mean[,,1]
omega_koval <- koval_fit$results$Theta$pcor$mean
theta_koval <- koval_fit$results$Theta$prec$mean
graph_nonsparse_koval <- list(beta = beta_koval, pcor = omega_koval, kappa = theta_koval)
saveRDS(graph_nonsparse_koval, here("data/graph_nonsparse_koval.RDS"))



```



# Synthetic DGP
To make it easier to manipulate centrality etc., we generate a synthetic DGP that is oriented at the numerical values in the fitted models.


## VAR Matrix

First, the nonsparse network: 
```{r}
graph_nonsp <- readRDS(here("data/graph_nonsparse.RDS"))

beta_nonsp <- round(graph_nonsp$beta, 3)
beta_nonsp_new <- matrix(c(0.30,  0.05,  0.10, -0.20,  0.10, -0.15,
                    0.30,  0.25,  0.05, -0.04,  0.02,  0.01,
                    0.10,  0.05,  0.20,-0.02, -0.03, -0.03,
                    -0.05, -0.05, -0.05, 0.2,  -0.03,  0.03,
                    0.05,  0.03,  0.03, -0.03,  0.15,  0.03,
                    -0.1, -0.03, -0.05, 0.05, -0.01,  0.10), 
                  nrow = 6, ncol = 6, byrow = TRUE)

# Calculate implied centrality values
beta_nonsp_temp <- beta_nonsp_new
diag(beta_nonsp_temp) <- 0
colSums(abs(beta_nonsp_temp))
rowSums(abs(beta_nonsp_temp))

# check stability
ev_b <- eigen(beta_nonsp_temp)$values
all(Re(ev_b) ^ 2 + Im(ev_b) ^ 2 < 1)

```

Then the sparse network: 
```{r}
# set all edges smaller that 0.05 to 0
beta_sp_new <- beta_nonsp_new
beta_sp_new[abs(beta_sp_new) < 0.05] <- 0

# Calculate implied centrality values
beta_sp_temp <- beta_sp_new
diag(beta_sp_temp) <- 0
colSums(abs(beta_sp_temp))
rowSums(abs(beta_sp_temp))

# calculate sparsity (number of nonzero edges in the off-diagonal)
sum(beta_sp_new == 0) / 30

# check stability
ev_b <- eigen(beta_sp_new)$values
all(Re(ev_b) ^ 2 + Im(ev_b) ^ 2 < 1)


```



## Contemporaneous Matrix

Use the kappa matrix of the nonsparse network as our basis. 
```{r}
graph_nonsp <- readRDS(here("data/graph_nonsparse.RDS"))
kappa_nonsp <- round(graph_nonsp$kappa, 3)

kappa_nonsp_new <- matrix(c(3.00, -1.00, -0.435, -0.060, -0.029, 0.141,
                      -1.00, 3.00, -0.781, 0.092, -0.100, 0.005,
                      -0.5, -0.78, 3.00, 0.245, -0.168, -0.015,
                      -0.2, 0.09, 0.25, 2.50, 0.350, -0.460,
                      -0.5, -0.10, -0.18, 0.40, 2.00, 0.197,
                      0.2, 0.05, -0.02, -0.40, 0.20, 1.5),
                    nrow = 6, ncol = 6, byrow = TRUE)
kappa_nonsp_new <- as.matrix(Matrix::forceSymmetric(kappa_nonsp_new, uplo = "L"))

# Obtain pcor matrix
pcor_nonsp_new <- -stats::cov2cor(kappa_nonsp_new)



# Calculate implied centrality values of partial correlations
pcor_nonsp_temp <- pcor_nonsp_new
diag(pcor_nonsp_temp) <- 0
colSums(abs(pcor_nonsp_temp))
rowSums(abs(pcor_nonsp_temp))

# check stability
ev_k <- eigen(kappa_nonsp_new)$values
all(ev_k >= 0)

```

Then create a sparse contemporaneous matrix: 
```{r}
kappa_sp_new <- kappa_nonsp_new

# obtain indices of all pcor_nonsp_new smaller that 0.05
idx <- which(abs(pcor_nonsp_new) < 0.05, arr.ind = TRUE)

# set them to zero in the kappa matrix
kappa_sp_new[idx] <- 0

# obtain pcor matrix
pcor_sp_new <- -stats::cov2cor(kappa_sp_new)

# calculate implied centrality values
pcor_sp_temp <- pcor_sp_new
diag(pcor_sp_temp) <- 0
colSums(abs(pcor_sp_temp))
rowSums(abs(pcor_sp_temp))

# calculate sparsity (number of nonzero edges in the off-diagonal)
sum(kappa_sp_new == 0) / 30

# check stability
ev_k <- eigen(kappa_sp_new)$values
all(ev_k >= 0)


```





Save the synthetic DGPs:

```{r}
graph_nonsp_synth <- list(beta = beta_nonsp_new, pcor = pcor_nonsp_new, kappa = kappa_nonsp_new)
saveRDS(graph_nonsp_synth, here("data/graph_nonsparse_synth.RDS"))
graph_sp_synth <- list(beta = beta_sp_new, pcor = pcor_sp_new, kappa = kappa_sp_new)
saveRDS(graph_sp_synth, here("data/graph_sparse_synth.RDS"))


```


## Alternative synthetic graph: Specify covariance directly

Here, we directly specify the residual covariance, which gives us easier control over the innovation variance etc. 
```{r}
matrix_upper <- matrix(c(1.00, 0.20, 0.10, 0.10, 0.10, -0.10,
                        -1.00, 1.00, 0.05, -0.04, -0.05, -0.05,
                        -0.50, -0.78, 1.00, 0.05, 0.05, -0.05,
                        -0.20, 0.09, 0.25, 1.00, -0.05, 0.05,
                        -0.50, -0.10, -0.18, 0.40, 1.00, -0.05,
                         0.20, 0.05, -0.02, -0.40, 0.20, 1.00),
                    nrow = 6, ncol = 6, byrow = TRUE)
# make symmetric
sigma_nonsp_new <- matrix_upper
sigma_nonsp_new[lower.tri(sigma_nonsp_new)] <- t(matrix_upper)[lower.tri(matrix_upper)]

# Obtain pcor matrix
pcor_nonsp_new <- -stats::cov2cor(solve(sigma_nonsp_new))
diag(pcor_nonsp_new) <- 0

# Calculate implied centrality values of partial correlations
colSums(abs(pcor_nonsp_new))

# check stability
ev_k <- eigen(kappa_nonsp_new)$values
all(ev_k >= 0)
```


Then create a sparse contemporaneous matrix: 

```{r}
sigma_sp_new <- sigma_nonsp_new

# set smallest half of values to zero
# first obtain all values in upper triangle
sigma_sp_new_upper <- sigma_sp_new[upper.tri(sigma_sp_new)]

# find number of unique elements in covariance matrix
n_val <- length(sigma_sp_new[upper.tri(sigma_sp_new)])

# then set smallest half to zero
sigma_sp_new_upper[order(abs(sigma_sp_new_upper))[1:(n_val * 0.5)]] <- 0

# then reattach to be covariance matrix again
sigma_sp_new[upper.tri(sigma_sp_new)] <- sigma_sp_new_upper
sigma_sp_new[lower.tri(sigma_sp_new)] <- t(sigma_sp_new)[lower.tri(sigma_sp_new)]
isSymmetric(sigma_sp_new)


# Obtain pcor and kappa matrix
kappa_sp_new <- solve(sigma_sp_new)
pcor_sp_new <- -stats::cov2cor(kappa_sp_new)
```
Save new DGPs
```{r}
graph_nonsp_synth_new <- list(beta = beta_nonsp_new, 
                          pcor = pcor_nonsp_new, 
                          sigma = sigma_nonsp_new,
                          kappa = kappa_nonsp_new)
graph_sp_synth_new <- list(beta = beta_sp_new, 
                          pcor = pcor_sp_new, 
                          sigma = sigma_sp_new,
                          kappa = kappa_sp_new)
# save as rds
saveRDS(graph_nonsp_synth_new, here("data/graph_nonsparse_synth_new.RDS"))
saveRDS(graph_sp_synth_new, here("data/graph_sparse_synth_new.RDS"))

```
Write to LaTeX:
```{r}
arr_to_latex(graph_nonsparse_synth_new$beta)
arr_to_latex(graph_nonsparse_synth_new$sigma)
```


# Synthetic DGP based on previous simulation studies. 

Instead of manually creating it, we base it on previous sim studies (see the preregistration for more information).
```{r}
test <- create_var_matrix(6, sparse = FALSE)
colSums(test)                            
rowSums(test)

arr_to_latex(test)
```




Then we can create the corresponding innovation covariance matrix:
```{r}
test_cov <- create_cov_matrix(6, sparse = FALSE)
colSums(test_cov)
rowSums(test_cov)
arr_to_latex(test_cov)
```



